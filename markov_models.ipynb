{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abbhimish/460-Week3-Rule-Based-Systems/blob/main/markov_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDnuCTiSCk8w"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IAT-ComputationalCreativity-Spring2025/Week3-Rule-Based-Systems/blob/main/markov_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYYt2WrwCk8z"
      },
      "source": [
        "# Markov Models Text Generation\n",
        "\n",
        "This notebook introduces Markov chains for text generation. We'll build a simple\n",
        "text generator that learns patterns from input text and generates new text with\n",
        "similar statistical properties."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "I6bcJsbVCk80"
      },
      "outputs": [],
      "source": [
        "# First, let's import our required libraries\n",
        "from collections import defaultdict\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9y2wladvCk81"
      },
      "source": [
        "## Building the Markov Chain\n",
        "\n",
        "A Markov chain represents sequences of states where the probability of each state\n",
        "depends only on the previous state(s). In our case, each state will be a sequence\n",
        "of words, and we'll predict the next word based on this sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gK6RokIpCk81"
      },
      "outputs": [],
      "source": [
        "def build_markov_chain(text, order=2):\n",
        "    \"\"\"\n",
        "    Build a Markov chain from input text.\n",
        "\n",
        "    Args:\n",
        "        text (str): Input text to learn from\n",
        "        order (int): Number of words to use as state (context)\n",
        "\n",
        "    Returns:\n",
        "        dict: Mapping from state tuples to lists of possible next words\n",
        "    \"\"\"\n",
        "    chain = defaultdict(list)\n",
        "    words = text.split()\n",
        "\n",
        "    for i in range(len(words) - order):\n",
        "        # Create state tuple from current words\n",
        "        state = tuple(words[i:i+order])\n",
        "        # Get the next word\n",
        "        next_word = words[i+order]\n",
        "        # Add to chain\n",
        "        chain[state].append(next_word)\n",
        "\n",
        "    return chain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pla4up0RCk81"
      },
      "source": [
        "## Generating Text\n",
        "\n",
        "Now we'll use our Markov chain to generate new text. We'll randomly select from\n",
        "the possible next words at each step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "d-pAXYqtCk82"
      },
      "outputs": [],
      "source": [
        "def generate_text(chain, num_words=30):\n",
        "    \"\"\"\n",
        "    Generate new text using the Markov chain.\n",
        "\n",
        "    Args:\n",
        "        chain (dict): Markov chain mapping states to possible next words\n",
        "        order (int): Length of state tuples\n",
        "        num_words (int): Number of words to generate\n",
        "\n",
        "    Returns:\n",
        "        str: Generated text\n",
        "    \"\"\"\n",
        "    # Start with a random state from the chain\n",
        "    words = list(random.choice(list(chain.keys())))\n",
        "    order = len(list(chain.keys())[0])\n",
        "\n",
        "    for _ in range(num_words - order):\n",
        "        state = tuple(words[-order:])\n",
        "        if state in chain:\n",
        "            next_word = random.choice(chain[state])\n",
        "            words.append(next_word)\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    return ' '.join(words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcNnjzKZCk82"
      },
      "source": [
        "## Part 3: Basic Example\n",
        "\n",
        "Let's try our text generator with a simple example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jX-8drdyCk82",
        "outputId": "1f2d884d-2e3a-4b57-d0dd-4adf3a1bd0df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I know -> ['you']\n",
            "know you -> ['(dry']\n",
            "you (dry -> ['up)']\n",
            "(dry up) -> ['Gotta']\n",
            "up) Gotta -> ['let']\n",
            "Gotta let -> ['the']\n",
            "let the -> ['pain']\n",
            "the pain -> ['see']\n",
            "pain see -> ['more']\n",
            "see more -> ['rain']\n",
            "more rain -> ['than']\n",
            "rain than -> ['most']\n",
            "than most -> ['do']\n",
            "most do -> ['Realize']\n",
            "do Realize -> ['every']\n",
            "Realize every -> ['moment']\n",
            "every moment -> [\"won't\"]\n",
            "moment won't -> ['be']\n",
            "won't be -> ['perfect,']\n",
            "be perfect, -> ['but']\n",
            "perfect, but -> ['I']\n",
            "but I -> ['do']\n",
            "I do -> ['Trying']\n",
            "do Trying -> ['all']\n",
            "Trying all -> ['the']\n",
            "all the -> ['mistakes']\n",
            "the mistakes -> ['that']\n",
            "mistakes that -> ['I']\n",
            "that I -> ['made']\n",
            "I made -> ['with']\n",
            "made with -> ['you,']\n",
            "with you, -> ['with']\n",
            "you, with -> ['you']\n",
            "with you -> ['You']\n",
            "you You -> ['do,']\n",
            "You do, -> ['you']\n",
            "do, you -> ['do,', 'do']\n",
            "you do, -> ['you']\n",
            "you do -> [\"You've\"]\n",
            "do You've -> ['got']\n",
            "You've got -> ['a', 'a', 'a', 'a', 'a', 'a', 'a-', 'a-', 'a-', 'a-']\n",
            "got a -> ['life', 'life', 'life', 'life', 'life', 'life']\n",
            "a life -> [\"You've\", \"You've\", 'Stay', \"You've\", \"You've\", 'Stay']\n",
            "life You've -> ['got', 'got', 'got', 'got']\n",
            "life Stay -> ['in', 'in']\n",
            "Stay in -> ['it', 'it-']\n",
            "in it -> [\"You've\"]\n",
            "it You've -> ['got']\n",
            "in it- -> ['(dry']\n",
            "it- (dry -> ['up,']\n",
            "(dry up, -> ['dry']\n",
            "up, dry -> ['up...)']\n",
            "dry up...) -> [\"You've\"]\n",
            "up...) You've -> ['got']\n",
            "got a- -> [\"You've\", \"You've\", \"You've\"]\n",
            "a- You've -> ['got', 'got', 'got']\n"
          ]
        }
      ],
      "source": [
        "# Sample text\n",
        "sample_text = \"\"\"\n",
        "I know you (dry up)\n",
        "Gotta let the pain see more rain than most do\n",
        "Realize every moment won't be perfect, but I do\n",
        "Trying all the mistakes that I made with you, with you\n",
        "You do, you do, you do\n",
        "You've got a life\n",
        "You've got a life\n",
        "You've got a life\n",
        "Stay in it\n",
        "You've got a life\n",
        "You've got a life\n",
        "You've got a life\n",
        "Stay in it- (dry up, dry up...)\n",
        "You've got a-\n",
        "You've got a-\n",
        "You've got a-\n",
        "You've got a-\n",
        "\"\"\"\n",
        "\n",
        "# Build the chain\n",
        "chain = build_markov_chain(sample_text)\n",
        "\n",
        "# Examine the chain\n",
        "for state, words in chain.items():\n",
        "    print(f\"{' '.join(state)} -> {words}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "It76WVjWCk83",
        "outputId": "c5fd17d8-9239-47a9-a6f9-5f899468e3af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated text:\n",
            "than most do Realize every moment won't be perfect, but I do Trying all the mistakes that I made with you, with you You do, you do You've got a\n"
          ]
        }
      ],
      "source": [
        "# Generate some text\n",
        "print(\"Generated text:\")\n",
        "print(generate_text(chain))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ps1b8okWCk83"
      },
      "source": [
        "## Student Tasks\n",
        "\n",
        "1. Basic Implementation:\n",
        "   - Try changing the order parameter in build_markov_chain\n",
        "   - What happens with order=1 vs order=3?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuynfpwnCk83",
        "outputId": "8da124c3-adbe-4829-ab70-29301538dd57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Order 1:\n",
            "it You've got a- You've got a life You've got a life You've got a- You've got a life You've got a life You've got a life You've got a-\n",
            "\n",
            "Order 3:\n",
            "let the pain see more rain than most do Realize every moment won't be perfect, but I do Trying all the mistakes that I made with you, with you You\n"
          ]
        }
      ],
      "source": [
        "# Task 1: Experiment with different orders\n",
        "print(\"\\nOrder 1:\")\n",
        "chain1 = build_markov_chain(sample_text, order=1)\n",
        "print(generate_text(chain1))\n",
        "\n",
        "print(\"\\nOrder 3:\")\n",
        "chain3 = build_markov_chain(sample_text, order=3)\n",
        "print(generate_text(chain3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RX4cNkoJCk83"
      },
      "source": [
        "2. Use Your Own Text:\n",
        "   Below, try using a different text source. You could use:\n",
        "   - Song lyrics\n",
        "   - Book excerpts\n",
        "   - Movie quotes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "cLtasvJPCk83"
      },
      "outputs": [],
      "source": [
        "# Task 2: Add your own text here\n",
        "your_text = \"\"\"\n",
        "[Hello how do you do??]\n",
        "Example:\n",
        "To be, or not to be, that is the question:\n",
        "Whether 'tis nobler in the mind to suffer\n",
        "The slings and arrows of outrageous fortune...\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7OCsNbyCk84"
      },
      "source": [
        "3. Advanced Implementation:\n",
        "   Add temperature-based sampling to control randomness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vj5NwPNbCk84",
        "outputId": "71976891-57e8-41c4-e96f-f4c3ec328aa0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Low temperature (more predictable):\n",
            "you do You've got a life You've got a life You've got a life You've got a life You've got a life You've got a life You've got a life\n",
            "\n",
            "High temperature (more random):\n",
            "with you You do, you do You've got a- You've got a- You've got a- You've got a- You've got a- You've got a- You've got a life Stay in\n"
          ]
        }
      ],
      "source": [
        "def generate_text_with_temperature(chain, temperature=1.0, num_words=30):\n",
        "    \"\"\"\n",
        "    Generate text with temperature-based sampling.\n",
        "    Lower temperature = more conservative/predictable\n",
        "    Higher temperature = more random/creative\n",
        "\n",
        "    Args:\n",
        "        chain (dict): Markov chain\n",
        "        temperature (float): Controls randomness (0.1 to 2.0 recommended)\n",
        "        order (int): Length of state tuples\n",
        "        num_words (int): Number of words to generate\n",
        "    \"\"\"\n",
        "    words = list(random.choice(list(chain.keys())))\n",
        "    order = len(list(chain.keys())[0])\n",
        "\n",
        "    for _ in range(num_words - order):\n",
        "        state = tuple(words[-order:])\n",
        "        if state in chain:\n",
        "            # Count frequencies of next words\n",
        "            next_words = chain[state]\n",
        "            word_counts = defaultdict(int)\n",
        "            for word in next_words:\n",
        "                word_counts[word] += 1\n",
        "\n",
        "            # Apply temperature\n",
        "            weights = [count ** (1.0 / temperature) for count in word_counts.values()]\n",
        "            total = sum(weights)\n",
        "            weights = [w/total for w in weights]\n",
        "\n",
        "            # Choose next word based on weighted probabilities\n",
        "            next_word = random.choices(list(word_counts.keys()), weights=weights)[0]\n",
        "            words.append(next_word)\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    return ' '.join(words)\n",
        "\n",
        "# Try different temperatures\n",
        "print(\"\\nLow temperature (more predictable):\")\n",
        "print(generate_text_with_temperature(chain, temperature=0.3))\n",
        "\n",
        "print(\"\\nHigh temperature (more random):\")\n",
        "print(generate_text_with_temperature(chain, temperature=2.0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkUeW3BOCk84"
      },
      "source": [
        "## Challenge Tasks:\n",
        "\n",
        "1. Implement a function to analyze the Markov chain:\n",
        "   - Count the number of unique states\n",
        "   - Find the most common transitions\n",
        "   - Calculate the average number of possible next words for each state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPEXf6vHCk84",
        "outputId": "5da380ae-74b8-4bae-cf20-8d888b9a76ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Chain Analysis:\n",
            "Number of unique states: 56\n",
            "Average transitions per state: 1.52\n",
            "\n",
            "Most common transitions:\n",
            "I know -> you (count: 1)\n",
            "know you -> (dry (count: 1)\n",
            "you (dry -> up) (count: 1)\n",
            "(dry up) -> Gotta (count: 1)\n",
            "up) Gotta -> let (count: 1)\n"
          ]
        }
      ],
      "source": [
        "def analyze_chain(chain):\n",
        "    \"\"\"\n",
        "    Analyze properties of the Markov chain.\n",
        "\n",
        "    Args:\n",
        "        chain (dict): Markov chain to analyze\n",
        "    \"\"\"\n",
        "    num_states = len(chain)\n",
        "    total_transitions = sum(len(next_words) for next_words in chain.values())\n",
        "    avg_transitions = total_transitions / num_states if num_states > 0 else 0\n",
        "\n",
        "    # Find most common next word for each state\n",
        "    most_common = {}\n",
        "    for state, next_words in chain.items():\n",
        "        word_counts = defaultdict(int)\n",
        "        for word in next_words:\n",
        "            word_counts[word] += 1\n",
        "        most_common[state] = max(word_counts.items(), key=lambda x: x[1])\n",
        "\n",
        "    print(f\"Number of unique states: {num_states}\")\n",
        "    print(f\"Average transitions per state: {avg_transitions:.2f}\")\n",
        "    print(\"\\nMost common transitions:\")\n",
        "    for state, (word, count) in list(most_common.items())[:5]:  # Show top 5\n",
        "        print(f\"{' '.join(state)} -> {word} (count: {count})\")\n",
        "\n",
        "# Analyze our chain\n",
        "print(\"\\nChain Analysis:\")\n",
        "analyze_chain(chain)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfwteZgiCk84"
      },
      "source": [
        "## Further Exploration:\n",
        "\n",
        "Other ideas to try:\n",
        "1. Modify the code to preserve punctuation\n",
        "2. Add start-of-sentence and end-of-sentence tokens\n",
        "3. Implement bi-directional generation\n",
        "4. Create a chain that works with characters instead of words\n",
        "5. Add input validation and error handling"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "iat460",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}